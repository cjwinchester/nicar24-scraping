{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e43afd-b469-49de-a614-78c571595e08",
   "metadata": {},
   "source": [
    "# Queensland workplace incidents\n",
    "\n",
    "Goal: Scrape [a paginated list of Queensland workplace incidents](https://www.worksafe.qld.gov.au/news-and-events/alerts) into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb1541-e1c5-40b9-b6e4-af852216b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080be819-a9bb-49aa-8f6c-c3202fa4263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of headers for output CSV\n",
    "csv_headers = [\n",
    "    'title',\n",
    "    'link',\n",
    "    'description',\n",
    "    'date'\n",
    "]\n",
    "\n",
    "# get a variable for the base url (will use a couple times)\n",
    "base_url = 'https://www.worksafe.qld.gov.au/news-and-events/alerts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284fb51-6d0d-428f-a8f9-c7f4cdff5b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need to figure out how many items are on each page,\n",
    "# and how many pages there are, in our initial request\n",
    "\n",
    "# request the page\n",
    "req = requests.get(base_url)\n",
    "\n",
    "# check for HTTP errors\n",
    "req.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5901f2b3-b4d4-4d4d-9ffe-d1867e427d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the HTML into soup\n",
    "soup = BeautifulSoup(req.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccda3804-615e-4bb4-af14-80fcf49b3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08787b0c-21c6-43e0-bd6c-ed40a96aca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch a list of pagination links, then grab the last one in the list ([-1])\n",
    "# and access its `href` attribute\n",
    "pagination = soup.find_all('a', {'class': 'pagination__link'})[-1]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d24a95-d81a-49b5-afa2-fe935c7c7b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc02eef3-f702-46fd-8577-bfd36b375669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final `start_rank` number -- the offset -- which is the \n",
    "# number after the `=` in the URL, and coerce to a number\n",
    "last_start_rank = int(pagination.split('=')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc679e9b-5a42-440c-b3d1-c4660b01bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_start_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3603db-c5d6-4c36-8cae-d230fdb8f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now figure out how many elements are on one page\n",
    "items = soup.find_all('li', {'class': 'search-results__item'})\n",
    "per_page = len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c18c32-e110-47e9-8cbe-e0f85ab6d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f342f2-1913-4e2f-a7f4-505c36e62ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a tracking list to hold the parsed data\n",
    "data = []\n",
    "\n",
    "# the `start_rank` param is basically, which item number should I start with\n",
    "# on this search results page? so we want to use the `range()` function to build\n",
    "# a range of numbers from 1 to `last_start_rank` (plus one, because the top end of\n",
    "# the range is always exclusive), counting by the number of items per page (12)\n",
    "\n",
    "for start_rank in range(1, last_start_rank+1, per_page):\n",
    "\n",
    "    # grab the page\n",
    "    req = requests.get(\n",
    "        base_url,\n",
    "        params={\n",
    "            'start_rank': start_rank\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # check for HTTP errors\n",
    "    req.raise_for_status()\n",
    "\n",
    "    print(f'Grabbing items starting at {start_rank} ...')\n",
    "\n",
    "    # turn the HTML into soup\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "\n",
    "    # grab a list of items on the page\n",
    "    items = soup.find_all('li', {'class': 'search-results__item'})\n",
    "\n",
    "    # loop over the list of items\n",
    "    for item in items:\n",
    "        hed = item.find('h4')\n",
    "        title = hed.text.strip()\n",
    "        link = hed.find('a')['href']\n",
    "        description = item.find('p').text.strip()\n",
    "        date = item.find('span').text.strip()\n",
    "\n",
    "        # build a list of data in the same order as the headers\n",
    "        row_data = [\n",
    "            title,\n",
    "            link,\n",
    "            description,\n",
    "            date\n",
    "        ]\n",
    "\n",
    "        data.append(row_data)\n",
    "\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a837f-3689-4e3a-9f1f-a6d4b4db2984",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b52157-0f91-4597-abee-4a54ecc04bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and write to file\n",
    "with open('qld-incidents.csv', 'w', newline='', encoding='utf-8') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(csv_headers)\n",
    "    writer.writerows(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
